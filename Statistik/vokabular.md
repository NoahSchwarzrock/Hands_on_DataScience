### **1. Arten der Statistik**

#### **a. Deskriptive Statistik**

- Beschreibt und analysiert vorhandene Daten. Ziel: Daten verständlich zusammenfassen.
- **Methoden:** Tabellen, Grafiken, Maße wie Mittelwert, Median, Standardabweichung.
- **Beispiel:** Durchschnittliches Einkommen in einer Region basierend auf erhobenen Daten.

#### **b. Induktive Statistik**

- Zieht Schlüsse von einer Stichprobe auf die Grundgesamtheit. Ziel: Allgemeine Aussagen treffen.
- **Methoden:** Hypothesentests, Konfidenzintervalle, Signifikanztests.
- **Beispiel:** Wahlumfrage mit 1.000 Personen → Vorhersage des Wahlergebnisses der gesamten Bevölkerung.

#### **c. Explorative Statistik**

- Sucht Muster und Zusammenhänge in Daten ohne vorherige Annahmen. Ziel: Hypothesen generieren.
- **Methoden:** Clusteranalyse, Korrelationsanalysen, Datenvisualisierung.
- **Beispiel:** Analyse von Kundenverhalten in einem Online-Shop, um neue Zielgruppen zu identifizieren.

---

### **2. Grundbegriffe**

#### **a. Statistische Einheit**

- Das Objekt, das untersucht wird.
- **Beispiel:** Einzelne Personen, Haushalte, Maschinen in einer Fabrik.

#### **b. Grundgesamtheit**

- Die Menge aller statistischen Einheiten, die untersucht werden.
- **Beispiel:** Alle Einwohner einer Stadt, alle verkauften Produkte eines Jahres.

#### **c. Merkmale**

- Eigenschaften der statistischen Einheiten, die erhoben werden.
- **Beispiel:** Alter, Geschlecht, Einkommen.

#### **d. Merkmalausprägung**

- Die konkreten Werte, die ein Merkmal annehmen kann.
- **Beispiel:**
  - Merkmal: Geschlecht → Merkmalausprägungen: männlich, weiblich.
  - Merkmal: Alter → Merkmalausprägungen: 25 Jahre, 30 Jahre usw.

#### **e. Statistische Variablen**

- Die abstrakte Bezeichnung für ein Merkmal, das unterschiedliche Werte annehmen kann.
- **Beispiel:**
  - Variable XX**X**: Einkommen → Werte: 30.000 €, 40.000 € usw.

#### **f. Merkmalsträger**

- Das Objekt oder die Einheit, an der Merkmale gemessen oder beobachtet werden.
- **Beispiel:**
  - Ein Auto (Merkmalsträger) mit den folgenden Merkmalen:
    - **Farbe** (Nominalskala): Rot, Blau, Schwarz.
    - **Beliebtheit (Ranking)** (Rangskala): Platz 1, Platz 2, Platz 3.
    - **Baujahr** (Intervallskala): 2000, 2010, 2020.
    - **Motorleistung (PS)** (Verhältnisskala): 100 PS, 200 PS, 300 PS.

---

### **3. Erhebungen**

#### **a. Gesamtheiten**

- Beschreibt die zu untersuchende Population (Grundgesamtheit) oder eine Teilmenge davon.
- **Beispiel:** Alle Schüler einer Schule oder nur die Abiturienten.

#### **b. Vollerhebung**

- Daten aller Elemente der Grundgesamtheit werden erhoben.
- **Beispiel:** Volkszählung, bei der jeder Einwohner befragt wird.

#### **c. Teilerhebung**

- Nur ein Teil der Grundgesamtheit wird untersucht (Stichprobe).
- **Beispiel:** Wahlumfrage mit einer repräsentativen Stichprobe.

#### **d. Sachliche, räumliche und zeitliche Abgrenzung**

- Definiert den Rahmen der Erhebung:

  - **Sachlich:** Welche Merkmale untersucht werden.
    **Beispiel:** Nur das Alter und Einkommen von Personen.
  - **Räumlich:** Der geografische Bereich.
    **Beispiel:** Einwohner einer Stadt oder eines Landes.
  - **Zeitlich:** Der Zeitraum der Erhebung.
    **Beispiel:** Daten aus dem Jahr 2023.

### Beispiel: Auto als Merkmalsträger

#### 1. **Nominalskala** :

- **Merkmal** : Farbe
- **Beispiele** : Rot, Blau, Schwarz
- **Beschreibung** :
- Farben sind rein kategorische Merkmale, die keine Reihenfolge haben.
- Sie können unterschieden, aber nicht sinnvoll geordnet werden.
- Operationen: Gleich oder Ungleich

#### 2. Ordinal- oder **Rangskala** :

- **Merkmal** : Beliebtheit (Ranking)
- **Beispiele** : Platz 1, Platz 2, Platz 3
- **Beschreibung** :
- Beliebtheit kann in eine Reihenfolge gebracht werden (Platz 1 ist beliebter als Platz 2).
- Die Abstände zwischen den Rängen sind jedoch nicht gleichmäßig oder messbar.
- Operationen: Gleich oder Ungleich, Größer oder Kleiner

#### **Kardinal oder metrische Skala:**

#### 3. **Intervallskala** :

- **Merkmal** : Baujahr des Autos
- **Beispiele** : 2000, 2010, 2020
- **Beschreibung** :
- Das Baujahr hat gleichmäßige Abstände zwischen den Werten (10 Jahre Unterschied zwischen 2000 und 2010).
- Es gibt jedoch keinen absoluten Nullpunkt, da das Jahr „0“ willkürlich gewählt wurde.
- Operationen: Gleich oder Ungleich, Größer oder Kleiner, Plus oder Minus

#### 4. **Verhältnisskala** :

- **Merkmal** : Motorleistung (PS)
- **Beispiele** : 100 PS, 200 PS, 300 PS
- **Beschreibung** :
- Die Motorleistung hat gleichmäßige Abstände (Unterschied von 100 PS ist immer gleichbedeutend).
- Es gibt einen absoluten Nullpunkt (0 PS bedeutet keine Leistung).
- Operationen: Gleich oder Ungleich, Größer oder Kleiner, Plus oder Minus, Mal oder Geteilt

### Statistische Verfahren: Diskret, Quasi-stetig und Stetig

Statistische Verfahren basieren auf der Art der Merkmale, die analysiert werden. Je nachdem, ob die Merkmale **diskret** , **quasi-stetig** oder **stetig** sind, unterscheiden sich die Methoden zur Gruppierung, Klassierung und der Berechnung der Klassenmitte.

---

### 1. **Diskrete Merkmale**

- **Definition** : Diskrete Merkmale haben endlich viele oder abzählbar unendlich viele Ausprägungen. Die Werte können nur bestimmte, voneinander abgegrenzte Zahlen annehmen (z. B. ganze Zahlen).
- **Beispiele** : Anzahl der Kinder in einer Familie, Würfelergebnisse, Anzahl der Autos in einer Garage.

#### Gruppierung und Klassierung:

- Bei diskreten Merkmalen ist oft keine Gruppierung nötig, da die Werte eindeutig abzählbar sind. Falls die Werte eine große Bandbreite haben, können sie in **Klassen** eingeteilt werden.
  - **Klasse** : Ein Bereich, der mehrere Werte umfasst (z. B. "0–2 Kinder", "3–5 Kinder").
  - **Klassenmitte** : Der Mittelwert der Grenzen einer Klasse (z. B. für die Klasse "0–2" ist die Klassenmitte (0+2)/2=1

#### Verfahren:

- Häufigkeitstabellen erstellen (absolute und relative Häufigkeit).
- Berechnung von Maßen wie Mittelwert oder Median, wenn Gruppierungen verwendet werden.

---

### 2. **Quasi-stetige Merkmale**

- **Definition** : Quasi-stetige Merkmale nehmen viele diskrete Werte an, die so dicht beieinander liegen, dass sie als stetig betrachtet werden können.
- **Beispiele** : Einkommen (oft gerundet auf ganze Zahlen), Alter (in Jahren angegeben, aber kontinuierlich interpretiert).

#### Gruppierung und Klassierung:

- Quasi-stetige Merkmale werden meist in Klassen eingeteilt, um die Daten zu vereinfachen und übersichtlicher darzustellen.
  - **Klassen** : Einkommen in Kategorien wie "0–1.000 €", "1.001–2.000 €".
  - **Klassenmitte** : Der Durchschnitt der Klassengrenzen (z. B. für die Klasse "0–1.000" ist die Klassenmitte (0+1.000)/2=500

#### Verfahren:

- Gruppierte Häufigkeitsverteilungen erstellen.
- Berechnung der Klassenmitte und darauf basierend des arithmetischen Mittels oder der Standardabweichung.

---

### 3. **Stetige Merkmale**

- **Definition** : Stetige Merkmale können jeden beliebigen Wert in einem Intervall annehmen. Sie werden oft auf einer kontinuierlichen Skala gemessen.
- **Beispiele** : Körpergröße, Gewicht, Temperatur.

#### Gruppierung und Klassierung:

- Stetige Merkmale werden immer in Klassen gruppiert, da es unmöglich ist, unendlich viele Werte darzustellen.
  - **Klassen** : Körpergrößen in Intervallen wie "160–165 cm", "165–170 cm".
  - **Klassenmitte** : Der Durchschnitt der Klassengrenzen (z. B. für die Klasse "160–165" ist die Klassenmitte (160+165)/2=162,5

#### Verfahren:

- Erstellung von Histogrammen und Dichtefunktionen.
- Berechnung von Maßen wie Mittelwert und Standardabweichung unter Berücksichtigung der Klassenmitten.

---

### **1. Univariate Datenanalyse**

Univariate Datenanalyse beschäftigt sich mit der Untersuchung **eines einzelnen Merkmals** oder einer Variablen. Ziel ist es, die Verteilung, zentrale Tendenzen und Streuungsmaße dieses Merkmals zu analysieren.

Beispiele:

- Körpergrößen einer Gruppe von Personen.
- Durchschnittstemperatur eines Monats.

Wichtige Werkzeuge:

- **Wertetabellen** (Häufigkeiten, kumulative Häufigkeiten).
- **Wertediagramme** (Balkendiagramme, Histogramme).
- **Geordnete Wertediagramme** (Daten in aufsteigender Reihenfolge sortieren).

---

### **Empirische Häufigkeitsfunktion**

#### **C.2.1.1 Absolute empirische Häufigkeitsfunktion**

Die **absolute empirische Häufigkeitsfunktion** beschreibt, wie oft ein bestimmter Messwert **x**k in einer Stichprobe vorkommt. Sie basiert auf den tatsächlichen Messdaten und ordnet jedem **x**k-Wert eine absolute Häufigkeit **n**k zu.

- Der Wert einer bestimmten Gruppe (z. B. schlecht, mittel, gut).
- Die absolute Häufigkeit, d. h., wie oft der Wert **x**k in der Stichprobe vorkommt.
- **„0 sonst“** : Werte, die in der Stichprobe nicht vorkommen, haben eine Häufigkeit von 0.

#### **C.2.1.3 Relative empirische Häufigkeitsfunktion**

Die **relative empirische Häufigkeitsfunktion** zeigt die Häufigkeit eines bestimmten Wertes im Verhältnis zur Gesamtanzahl der Messwerte.

- **Relative Häufigkeit** : Wird berechnet, indem die absolute Häufigkeit **n**k durch die Gesamtanzahl **n** der Messwerte geteilt wird.
- **Prozentdarstellung** : Die relative Häufigkeit kann als Bruch oder in Prozent angegeben werden.
- **„0 sonst“** : Werte, die in der Stichprobe nicht vorkommen, haben eine relative Häufigkeit von 0.

### **Stabdiagramme und Histogramme**

#### **Stabdiagramme**

Ein **Stabdiagramm** ist eine grafische Darstellung der Häufigkeitsverteilung von diskreten Daten. Es zeigt die Werte (z. B. absolute oder relative Häufigkeiten) durch vertikale Stäbe.

- **X-Achse** : Werte der Daten (z. B. Kategorien oder Messwerte).
- **Y-Achse** : Absolute oder relative Häufigkeiten.
- **Verwendung** :
- Wird genutzt, wenn die Daten **diskret** sind und wenige verschiedene Werte haben.
- **Eigenschaften** :
- Die Stäbe sind voneinander getrennt.
- Ideal für Häufigkeitsverteilungen, die direkt auf den erhobenen Daten basieren.

#### ** Histogramme**

Ein **Histogramm** ist eine grafische Darstellung der Häufigkeitsverteilung von gruppierten (kontinuierlichen) Daten. Es ähnelt dem Stabdiagramm, aber die Stäbe sind aneinander gereiht, da die Intervalle zusammenhängen.

- **X-Achse** : Klassenintervalle (z. B. 10–20, 20–30).
- **Y-Achse** : Absolute oder relative Häufigkeiten der Klassen.
- **Verwendung** :
- Wird genutzt, wenn die Daten **kontinuierlich** sind oder viele verschiedene Werte haben.
- **Eigenschaften** :
- Breite der Stäbe entspricht der Klassenbreite.
- Höhe der Stäbe zeigt die Häufigkeit.
- Sind die Klassen unterschiedlich breit, muss man die Höhe der Rechtecke anpassen, damit die Fläche proportional zu den Häufigkeiten ist .

---

### **Empirische Verteilungsfunktion und Treppendiagramm**

#### **Was ist die empirische Verteilungsfunktion?**

Die **empirische Verteilungsfunktion** zeigt an, wie viele Beobachtungswerte kleiner oder gleich einem bestimmten Grenzwert sind. Sie beantwortet Fragen wie:
_„Wie viele Prozent der Arbeitnehmer verdienen maximal 30.000 EUR im Jahr?“_

#### **Eigenschaften**

1. **Werte kleiner als der kleinste Messwert** : Die Funktion ordnet solchen Werten die Häufigkeit 00**0** zu.
   _Beispiel: „0 Messwerte sind kleiner als der kleinste Messwert.“_
2. **Werte innerhalb der gemessenen Daten** : Die Funktion summiert die Häufigkeiten aller Werte, die kleiner oder gleich dem betrachteten Wert sind.
   _Beispiel: „Die Summe aller Häufigkeiten bis zum aktuellen Messwert.“_
3. **Werte größer als der größte Messwert** : Solche Werte erhalten die Häufigkeit der Gesamtanzahl aller Beobachtungen.
   _Beispiel: „Alle Messwerte sind kleiner oder gleich einem Wert, der größer als der größte Messwert ist.“_

#### **Zusammenfassung**

- Die Funktion zeigt kumulierte absolute oder relative Häufigkeiten.
- Für die relative Häufigkeit wird die absolute Summenhäufigkeit durch die Anzahl der Messwerte geteilt
- Sie wird grafisch als **Treppendiagramm** dargestellt, wo die Treppenform den sprunghaften Anstieg der Häufigkeiten bei jedem Messwert verdeutlicht.

### **Treppendiagramm in der empirischen Verteilungsfunktion**

Ein **Treppendiagramm** ist eine grafische Darstellung der empirischen Verteilungsfunktion. Es zeigt die kumulierten Häufigkeiten von Beobachtungswerten und hat eine charakteristische treppenartige Form, da die Häufigkeiten sprunghaft ansteigen.

### **Merkmale eines Treppendiagramms**

1. **X-Achse (Beobachtungswerte)** :

- Zeigt die möglichen Werte der Messung (z. B. Einkommen, Alter, Gewicht).

1. **Y-Achse (Kumulierte Häufigkeit)** :

- Zeigt die kumulierte Anzahl (absolute Verteilungsfunktion) oder den kumulierten Anteil (relative Verteilungsfunktion) der Beobachtungswerte.

1. **Treppenform** :

- Jeder Sprung in der Treppe repräsentiert die kumulierte Häufigkeit bis zu einem bestimmten Wert.
- Zwischen zwei Messwerten bleibt die Funktion konstant.

1. **Grenzwerte** :

- Für Werte kleiner als der kleinste Messwert ist die Häufigkeit 00**0**.
- Für Werte größer als der größte Messwert erreicht die Funktion das Maximum (z. B. 100 % bei relativer Häufigkeit oder die Gesamtanzahl bei absoluter Häufigkeit).

---

### **Modalwert, Mittelwert und Median**

#### **1. Modalwert (Modus)**

- **Definition** : Der **Modalwert** ist der häufigste Wert in einer Datenreihe.
- **Verwendung** :
- Wird genutzt, um den typischsten oder am häufigsten vorkommenden Wert darzustellen.
- Kann für **nominale Daten** (z. B. Farben, Kategorien) und **metrische Daten** verwendet werden.
- **Beispiel** :
- Daten: [1,2,2,3,3,3,4][1, 2, 2, 3, 3, 3, 4]**[**1**,**2**,**2**,**3**,**3**,**3**,**4**]**
- Modalwert: 33**3** (kommt am häufigsten vor).
- **Wann benutzt man den Modalwert?**
  - Wenn der häufigste Wert wichtig ist (z. B. die beliebteste Farbe, meistverkauftes Produkt).
  - Bei nominalen Skalen, da Mittelwert und Median hier nicht sinnvoll sind.

---

#### **2. Mittelwert (Mean)**

- **Definition** : Der **Mittelwert** (Durchschnitt) wird berechnet, indem man die Summe aller Werte durch die Anzahl der Werte teilt.

Mittelwert=Summe der WerteAnzahl der Werte\text{Mittelwert} = \frac{\text{Summe der Werte}}{\text{Anzahl der Werte}}**Mittelwert**=**Anzahl der Werte**Summe der Werte**\*** **Verwendung** :

- Zeigt den Durchschnitt der Daten.
- Empfindlich gegenüber **Ausreißern** (extrem kleine oder große Werte).
- **Beispiel** :
- Daten: [1,2,3,4,100][1, 2, 3, 4, 100]**[**1**,**2**,**3**,**4**,**100**]**
- Mittelwert: (1+2+3+4+100)/5=22(1 + 2 + 3 + 4 + 100) / 5 = 22**(**1**+**2**+**3**+**4**+**100**)**/5**=**22.
- **Wann benutzt man den Mittelwert?**
  - Bei **symmetrischen Verteilungen** ohne Ausreißer.
  - In der Statistik, wenn die Gesamtheit repräsentiert werden soll (z. B. Durchschnittsgehälter).

---

#### **3. Median**

- **Definition** : Der **Median** ist der mittlere Wert in einer geordneten Datenreihe.
- Bei einer ungeraden Anzahl: Der Wert genau in der Mitte.
- Bei einer geraden Anzahl: Der Durchschnitt der beiden mittleren Werte.
- **Verwendung** :
- Zeigt den zentralen Wert der Daten.
- Robuster gegenüber **Ausreißern** als der Mittelwert.
- **Beispiel** :
- Daten (ungerade): [1,2,3,4,5][1, 2, 3, 4, 5]**[**1**,**2**,**3**,**4**,**5**]** → Median: **3**.
- Daten (gerade): [1,2,3,4,100,200][1, 2, 3, 4, 100, 200]**[**1**,**2**,**3**,**4**,**100**,**200**]** → Median: (3+4)/2=3.5
- **Wann benutzt man den Median?**
  - Bei **asymmetrischen Verteilungen** oder Daten mit Ausreißern.
  - Wenn der mittlere Wert der Daten wichtiger ist als der Durchschnitt (z. B. Haushaltseinkommen).

---

### **Varianz und Standardabweichung – Prägnante Übersicht**

#### **Varianz**

- **Definition** : Misst die durchschnittliche quadrierte Abweichung der Datenwerte vom Mittelwert.
- **Vorteile** :
- Präzise Darstellung der Streuung.
- Grundlage für viele statistische Verfahren (z. B. ANOVA, Regressionsanalyse).
- **Nachteil** :
- Einheit ist quadriert, was die Interpretation erschwert.
- **Verwendung** :
- Für mathematische Analysen und Verfahren, die präzise Streuungsmaße benötigen.

#### **Standardabweichung**

- **Definition** : Quadratwurzel der Varianz; gibt die durchschnittliche Abweichung der Datenwerte vom Mittelwert an.
- **Vorteile** :
- Einheit ist identisch mit den Daten, daher leicht interpretierbar.
- Ermöglicht einfache Vergleiche zwischen Datensätzen.
- **Nachteil** :
- Weniger empfindlich für große Abweichungen (im Vergleich zur Varianz).
- **Verwendung** :
- Für die Kommunikation von Streuung, da sie intuitiver ist.

### **Zusammenfassung**

- **Varianz** ist ein präzises Maß für die Streuung, aber schwer zu interpretieren, da sie quadrierte Einheiten hat.
- **Standardabweichung** ist die intuitivere und praktischere Maßzahl, da sie dieselbe Einheit wie die Daten hat.
- Beide sind unverzichtbar für das Verständnis von Streuung und für viele statistische Anwendungen.

---

### Lineare Regression

* **Gegebene Daten:**
  * Du hast xx**x**- und yy**y**-Werte (z. B. unabhängige und abhängige Variablen).
* **Ziel:**
  * Finde eine Gerade (y=a+b⋅xy = a + b \cdot x**y**=**a**+**b**⋅**x**), die die Datenpunkte bestmöglich beschreibt.
* **Fehlerfunktion:**
  * Berechne die Abweichungen zwischen den tatsächlichen yy**y**-Werten und den Werten, die durch die Gerade vorhergesagt werden. Ziel ist es, diese Fehler so klein wie möglich zu machen.
* **Partielle Ableitungen:**
  * Leite die Fehlerfunktion nach aa**a** (Achsenabschnitt) und bb**b** (Steigung) ab, um die optimalen Werte zu finden.
* **Gleichungssystem erstellen:**
  * Stelle zwei Gleichungen auf, die aus den Ableitungen resultieren.
* **Gleichungssystem lösen:**
  * Löse die Gleichungen, um die Werte für aa**a** (Achsenabschnitt) und bb**b** (Steigung) zu erhalten.
* **Ergebnis:**
  * Setze aa**a** und bb**b** in die Geradengleichung ein und erhalte die fertige Regressionsgerade.
* **Weitere Schritte:**
  * Nutze die Regressionsgerade, um Vorhersagen für neue xx**x**-Werte zu machen und das Modell zu bewerten (z. B. durch Residuenanalyse oder Gütemaße wie R2R^2**R**2).

---

### Quantile und Boxplots (mit Beispiel)

#### **1. Quantile**

Quantile sind Werte, die einen geordneten Datensatz in Anteile teilen. Sie helfen, Lage und Streuung der Daten zu beschreiben.

* **Definition des pp**p**-Quantils** :
  Ein pp**p**-Quantil (QpQ_p**Q**p) ist der Wert, unter dem p⋅100%p \cdot 100\%**p**⋅**100%** der Werte liegen. Zum Beispiel:
* Q0.25Q_{0.25}**Q**0.25: 25% der Werte liegen darunter (unteres Quartil).
* Q0.5Q_{0.5}**Q**0.5: Median (50% der Werte liegen darunter).
* Q0.75Q_{0.75}**Q**0.75: 75% der Werte liegen darunter (oberes Quartil).
* **Berechnung** :

1. Daten sortieren.
2. Multipliziere pp**p** mit nn**n** (Anzahl der Datenpunkte):
   * **Wenn p⋅np \cdot n**p**⋅**n** eine ganze Zahl ist** : Mittelwert der Werte an den Positionen p⋅np \cdot n**p**⋅**n** und p⋅n+1p \cdot n + 1**p**⋅**n**+**1**.
   * **Wenn p⋅np \cdot n**p**⋅**n** keine ganze Zahl ist** : Aufrunden und den entsprechenden Wert nehmen.

---

#### **Beispiel** : Datenreihe: [10,12,15,18,20,22,25,30,35,40][10, 12, 15, 18, 20, 22, 25, 30, 35, 40]**[**10**,**12**,**15**,**18**,**20**,**22**,**25**,**30**,**35**,**40**]** (n=10n = 10**n**=**10**)

1. **Median (Q0.5Q_{0.5}**Q**0.5****):**
   * p⋅n=0.5⋅10=5p \cdot n = 0.5 \cdot 10 = 5**p**⋅**n**=**0.5**⋅**10**=**5**. Eine ganze Zahl!
   * Mittelwert der 5. und 6. Werte: (20+22)/2=21(20 + 22) / 2 = 21**(**20**+**22**)**/2**=**21.
2. **Unteres Quartil (Q0.25Q_{0.25}**Q**0.25****):**
   * p⋅n=0.25⋅10=2.5p \cdot n = 0.25 \cdot 10 = 2.5**p**⋅**n**=**0.25**⋅**10**=**2.5**. Keine ganze Zahl → Aufrunden.
   * Wert an Position 3: 1515**15**.
3. **Oberes Quartil (Q0.75Q_{0.75}**Q**0.75****):**
   * p⋅n=0.75⋅10=7.5p \cdot n = 0.75 \cdot 10 = 7.5**p**⋅**n**=**0.75**⋅**10**=**7.5**. Keine ganze Zahl → Aufrunden.
   * Wert an Position 8: 3030**30**.

---

#### **2. Boxplot**

Ein **Boxplot** stellt die Verteilung der Daten grafisch dar:

* **Box** : Zwischen unterem Quartil (Q0.25Q_{0.25}**Q**0.25) und oberem Quartil (Q0.75Q_{0.75}**Q**0.75).
* **Median** : Linie innerhalb der Box.
* **Whisker** : Linien zu Minimum und Maximum (außer bei Ausreißern).

---

#### **Lorenzkurve**

* Die Lorenzkurve zeigt den kumulierten Anteil der **Population** (x-Achse) im Vergleich zum kumulierten Anteil der **Merkmalsmasse** (y-Achse).
* **Beispiel** :
* x=0.5x = 0.5**x**=**0.5**: Die ärmsten 50% der Bevölkerung besitzen y=10%y = 10\%**y**=**10%** des Gesamteinkommens.
* **Interpretation** :
* Die 45°-Linie (Gleichverteilungslinie) repräsentiert eine  **völlig gleichmäßige Verteilung** .
* Je stärker die Lorenzkurve unter der 45°-Linie liegt, desto ungleicher ist die Verteilung (größere Konzentration).

---

### **Berechnung der Konzentrationsfläche**

* Die Fläche zwischen der **Lorenzkurve** und der 45°-Linie wird verwendet, um die Konzentration zu messen.
* Diese Fläche wird in zwei Teile zerlegt:
  1. **Fläche unter der Lorenzkurve** (AA**A**)
  2. **Gesamte Fläche unter der 45°-Linie** (A+B=0.5A + B = 0.5**A**+**B**=**0.5**)
* **Konzentrationsfläche (BB**B**):**
  B=0.5−AB = 0.5 - A**B**=**0.5**−**A**
  * 0.50.5**0.5**: Fläche unter der 45°-Linie.
  * AA**A**: Fläche unter der Lorenzkurve (kann durch Integration oder Summation approximiert werden).

---

### **Gini-Koeffizient**

#### **Definition**

* Der **Gini-Koeffizient** (GG**G**) ist ein Maß für die Ungleichverteilung und wird auf Basis der Lorenzkurve berechnet.
* Er ist definiert als das Verhältnis der Konzentrationsfläche (BB**B**) zur gesamten Fläche unter der 45°-Linie (A+B=0.5A + B = 0.5**A**+**B**=**0.5**):
  G=B0.5=2⋅BG = \frac{B}{0.5} = 2 \cdot B**G**=**0.5**B****=**2**⋅**B**

#### **Wertebereich**

* G=0G = 0**G**=**0**: Völlige Gleichverteilung (Lorenzkurve = 45°-Linie).
* G=1G = 1**G**=**1**: Maximale Konzentration (eine Person besitzt alles).

---

### **Normierter Gini-Koeffizient**

#### **Problem mit dem Gini-Koeffizienten**

* Der Gini-Koeffizient erreicht auch bei maximaler Konzentration (G=1G = 1**G**=**1**)  **nicht immer den Wert 1** , weil die Lorenzkurve niemals die gesamte Fläche unter der 45°-Linie einnehmen kann (z. B. bei diskreten Daten).
* Dies macht die Interpretation schwierig, da "maximale Konzentration" nicht mit einem normierten Maß von 1 dargestellt wird.

#### **Lösung: Normierung**

* Der **normierte Gini-Koeffizient** (G∗G^***G**∗) skaliert GGG**, sodass er maximal 1 erreicht.
* Formel:
  G∗=nn−1⋅GG^* = \frac{n}{n-1} \cdot G**G**∗**=**n**−**1**n****⋅**G
  * nn**n**: Anzahl der Beobachtungen.
  * n−1n-1**n**−**1**: Maximale mögliche Konzentrationsfläche.

#### **Vorteile des normierten Gini-Koeffizienten**

* Beseitigt die Abhängigkeit von der Anzahl der Beobachtungen (nn**n**).
* Ermöglicht bessere Vergleichbarkeit zwischen verschiedenen Datensätzen.

---

### **Zusammenfassung**

| Maß                                          | Beschreibung                                                                                                             |
| --------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| **Lorenzkurve**                         | Graphische Darstellung der Verteilung eines Merkmals, basierend auf kumulierten Anteilen der Masse.                      |
| **Konzentrationsfläche**               | Fläche zwischen der Lorenzkurve und der 45°-Linie; repräsentiert die Ungleichheit.                                    |
| **Gini-Koeffizient (GG**G**)**          | Maß für die Ungleichverteilung, basierend auf der Konzentrationsfläche (G=2⋅BG = 2 \cdot B**G**=**2**⋅**B**). |
| **Normierter Gini (G∗G^***G**∗)** | Skaliert den Gini-Koeffizienten, sodass maximale Konzentration den Wert 1 erreicht.                                      |

---

### **Bivariate und multivariate Analyse**

#### **Bivariate Analyse**

* **Untersuchung von zwei Merkmalen** und deren Beziehung.
* Ziel: Erkennen von Zusammenhängen (z. B. Zeit online xx**x** und erinnerte Werbebotschaften yy**y**).
* Darstellungsmethoden:
  * **Streudiagramm** : Zeigt die Verteilung von Datenpunkten in einem Koordinatensystem.

#### **Multivariate Analyse**

* **Untersuchung von mehr als zwei Merkmalen** .
* Ziel: Komplexere Zusammenhänge erkennen (z. B. Einfluss von Wassermenge, Sonnenlicht und Dünger auf Pflanzenwachstum).

---

### **Kontingenz- oder Korrelationstabelle**

#### **Definition**

* Tabelle, die die gemeinsamen Häufigkeiten zweier Merkmale darstellt.
* **Zeilen** : Klassen/Ausprägungen des ersten Merkmals.
* **Spalten** : Klassen/Ausprägungen des zweiten Merkmals.
* **Zellen** : Häufigkeiten für jede Kombination der Merkmalsausprägungen.

#### **Interpretation**

* Zeigt, welche Merkmalskombinationen besonders häufig oder selten auftreten.
* Kann absolute oder relative Häufigkeiten enthalten.

#### **Beispiel:**

| Zeit online (h/Tag) | [4; 8) | [8; 12) | [12; 16] | Gesamt |
| ------------------- | ------ | ------- | -------- | ------ |
| [0; 1.5)            | 4      | 3       | 0        | 7      |
| [1.5; 3.0)          | 0      | 2       | 9        | 11     |
| [3.0; 5.0]          | 0      | 4       | 3        | 7      |
| **Gesamt**    | 4      | 9       | 12       | 25     |

---

### **Streifendiagramm**

#### **Definition**

* Grafische Darstellung einer Kontingenztabelle.
* Jeder **Streifen repräsentiert eine Klasse** eines Merkmals und wird entsprechend der relativen Häufigkeiten des zweiten Merkmals unterteilt.

#### **Beispiel:**

* Zeit online ([0;1.5), [1.5;3.0), [3.0;5.0]) als Streifen.
* Streifenanteile zeigen relative Häufigkeiten der Werbebotschaftsklassen ([4;8), [8;12), [12;16]).

---

### **Korrelationsanalyse**

#### **Worum geht's?**

* Die Korrelationsanalyse misst den Zusammenhang zwischen zwei Merkmalen (xx**x** und yy**y**).
* Ziel: Herausfinden, ob Werte eines Merkmals steigen/fallen, wenn Werte eines anderen steigen/fallen.

#### **Anwendungsbereich**

* Liefert Hinweise auf Zusammenhänge ohne tiefgehende Analyse.
* Gibt erste Hinweise, wo genauere Untersuchungen sinnvoll sein könnten.
* Wichtig: Korrelation ≠ Kausalität.

---

### **Bravais-Pearson Korrelationskoeffizient**

#### **Definition**

* Misst, wie stark die Werte zweier Merkmale auf einer **linearen Geraden** liegen.
* Wertebereich:
  * r=+1r = +1**r**=**+**1: Perfekter positiver linearer Zusammenhang.
  * r=−1r = -1**r**=**−**1: Perfekter negativer linearer Zusammenhang.
  * r=0r = 0**r**=**0**: Kein linearer Zusammenhang.

#### **Berechnung**

Formel:

r=Kovarianz(x,y)Standardabweichung(x)⋅Standardabweichung(y)r = \frac{\text{Kovarianz} (x, y)}{\text{Standardabweichung}(x) \cdot \text{Standardabweichung}(y)}**r**=**Standardabweichung**(**x**)**⋅**Standardabweichung**(**y**)**Kovarianz**(**x**,**y**)***  **Kovarianz** : Gemeinsame Streuung der Merkmale xx**x** und yy**y**.

* **Standardabweichung** : Streuung der einzelnen Merkmale.

#### **Interpretation**

* Wertepaare auf einer positiven/negativen Gerade → r≈+1/−1r \approx +1 / -1**r**≈**+**1/**−**1.
* Wertepaare ohne erkennbare Struktur → r≈0r \approx 0**r**≈**0**.

### **Wichtige Hinweise**

1. **Korrelation ist nicht gleich Kausalität** :

* Ein Zusammenhang kann auch durch eine dritte (unbekannte) Variable beeinflusst sein.

1. **Nur für lineare Zusammenhänge geeignet** :

* Nichtlineare Zusammenhänge können r=0r = 0**r**=**0** ergeben, selbst wenn ein Zusammenhang besteht.

1. **Ausreißer entfernen** :

* Einzelne extrem abweichende Werte können rr**r** stark verzerren.

### **Beispiel**

* **Datensatz** : Entfernung vom Stadtzentrum (xx**x**) und Wochenumsatz (yy**y**):
* r=−0.97r = -0.97**r**=**−**0.97: Starker negativer linearer Zusammenhang.
* Interpretation: Je weiter ein Geschäft vom Zentrum entfernt liegt, desto geringer der Umsatz.

---

### **Rangkorrelation nach Spearman**

#### **Definition**

* Die **Rangkorrelation nach Spearman** (ρ\rho**ρ**, gesprochen "Rho") misst den **monotonen Zusammenhang** zwischen zwei Variablen, basierend auf deren **Rangplätzen** statt auf den ursprünglichen Werten.
* Sie ist ein **nichtparametrisches Maß** und eine Alternative zum Pearson-Korrelationskoeffizienten.

### **Formel**

ρ=1−6⋅∑di2n⋅(n2−1)\rho = 1 - \frac{6 \cdot \sum d_i^2}{n \cdot (n^2 - 1)}**ρ**=**1**−**n**⋅**(**n**2**−**1**)**6**⋅**∑**d**i**2***** did_i**d**i****: Differenz der Ränge zwischen zwei Variablen für Beobachtung ii**i**.

* nn**n**: Anzahl der Beobachtungen.

### **Wann verwendet man die Rangkorrelation?**

1. **Datenbasis** :

* Wenn die Daten **nicht normalverteilt** sind oder **Ausreißer** vorhanden sind.
* Bei **ordinalskalierten** Daten, bei denen die Reihenfolge der Werte relevant ist (aber nicht deren exakter Abstand).

1. **Ziel** :

* Untersuchung eines  **monotonen Zusammenhangs** :
  Wenn eine Variable steigt, steigt (oder fällt) die andere, aber nicht unbedingt linear.

### **Unterschied zur Pearson-Korrelation**

* **Pearson-Korrelation** misst **lineare Zusammenhänge** und basiert auf den exakten Werten.
* **Spearman-Korrelation** misst **monotone Zusammenhänge** und verwendet  **Rangplätze** .

### **Beispiel**

| Beobachtung | xx**x** | Rang vonxx**x** | yy**y** | Rang vonyy**y** | Differenz (did_i**d**i) | di2d_i^2**d**i**2** |
| ----------- | ------------- | --------------------- | ------------- | --------------------- | ----------------------------- | ------------------------------- |
| 1           | 3             | 2                     | 8             | 1                     | 1                             | 1                               |
| 2           | 1             | 1                     | 12            | 3                     | -2                            | 4                               |
| 3           | 7             | 3                     | 10            | 2                     | 1                             | 1                               |

Einsetzen der Werte in die Formel ergibt den Spearman-Koeffizienten ρ\rho**ρ**.

### **Vorteile**

* **Robust gegenüber Ausreißern** .
* Verwendbar bei **ordinalskalierten** Daten.
* Liefert Ergebnisse für monotone, nichtlineare Zusammenhänge.

### **Zusammengefasst**

Die **Rangkorrelation nach Spearman** misst monotone Zusammenhänge zwischen zwei Variablen. Sie eignet sich besonders für ordinalskalierte oder nicht normalverteilte Daten und bietet eine robuste Alternative zur Pearson-Korrelation.

---

# Zeitreihenanalyse: Komponenten und Filtermethoden

## Komponenten der Zeitreihenanalyse

### 1. **Trend**

* **Definition** : Ein langfristiger Aufwärts- oder Abwärtstrend in den Daten, der eine allgemeine Richtung über einen längeren Zeitraum zeigt.
* **Beispiele** :
* Wachsender Umsatz eines Unternehmens über Jahre.
* Anstieg der globalen Durchschnittstemperatur.

### 2. **Zyklus**

* **Definition** : Schwankungen, die über einen längeren Zeitraum auftreten und oft mit wirtschaftlichen oder natürlichen Zyklen zusammenhängen.
* **Beispiele** :
* Wirtschaftliche Konjunkturzyklen (Boom und Rezession).
* Natürliche Wetterphänomene wie El Niño.

### 3. **Saison**

* **Definition** : Regelmäßige und wiederholbare Muster innerhalb eines festen Zeitrahmens (z. B. ein Jahr, ein Monat).
* **Beispiele** :
* Höherer Einzelhandelsumsatz in der Weihnachtszeit.
* Temperaturveränderungen über Jahreszeiten hinweg.

# Filtermethoden in der Zeitreihenanalyse

### Was macht der gleitende Durchschnitt?

Der **gleitende Durchschnitt** glättet Daten, indem er das Mittel der Werte in einem definierten **Fenster** berechnet. Das Fenster bewegt sich schrittweise über die Zeitreihe, wodurch für jeden Zeitpunkt ein neuer Durchschnittswert berechnet wird.

* **Fenstergröße** : Gibt an, wie viele Datenpunkte für die Berechnung des Durchschnitts verwendet werden (z. B. 3 Werte bei einem Fenster von 3).
* **Bewegung über die Daten** : Das Fenster "gleitet" von Anfang bis Ende der Zeitreihe, daher der Name "gleitender Durchschnitt".

---

### Betrachtung der gesamten Datenreihe?

* **Nein** , der gleitende Durchschnitt berücksichtigt nicht alle Daten der gesamten Zeitreihe gleichzeitig.
* Stattdessen wird immer nur ein **lokaler Ausschnitt** (definiert durch die Fenstergröße) betrachtet, um Trends oder Muster innerhalb dieses Bereichs zu glätten.

Beispiel:

* Zeitreihe: `[2, 4, 6, 8, 10, 12]`
* Fenstergröße: 3
* Berechnungen:
  * Mittelwert der ersten 3 Werte: (2+4+6)/3=4\text{Mittelwert der ersten 3 Werte: } (2 + 4 + 6) / 3 = 4**Mittelwert der ersten 3 Werte: **(**2**+**4**+**6**)**/3**=**4**
  * Na¨chster Mittelwert: (4+6+8)/3=6\text{Nächster Mittelwert: } (4 + 6 + 8) / 3 = 6**N**a**¨**chster Mittelwert: **(**4**+**6**+**8**)**/3**=**6
  * usw.

---

### Warum ist das Fenster wichtig?

Das Fenster bestimmt:

* **Granularität** der Glättung:
  * **Kleines Fenster** : Schneller auf Änderungen reagieren, aber weniger geglättet.
  * **Großes Fenster** : Stärkere Glättung, aber langsame Reaktion.
* **Anzahl der berücksichtigten Werte** :
* Ein gleitender Durchschnitt mit einem Fenster von 3 bezieht nur 3 Werte auf einmal ein – unabhängig davon, wie lang die Zeitreihe ist.

---

### **Exponentielle Glättung**

#### Was ist das?

* Eine fortgeschrittene Methode, die den Einfluss vergangener Datenpunkte exponentiell verringert, je weiter sie in der Vergangenheit liegen.
* **Vorteil** : Gibt neueren Daten mehr Gewicht, was zu schnellerer Anpassung an Veränderungen führt.

#### Unterschiede zum gleitenden Durchschnitt:

| **Merkmal**                | **Gleitender Durchschnitt**                                 | **Exponentielle Glättung**                  |
| -------------------------------- | ----------------------------------------------------------------- | -------------------------------------------------- |
| **Gewichtung der Daten**   | Alle berücksichtigten Punkte werden gleich gewichtet.            | Neueren Punkten wird mehr Gewicht gegeben.         |
| **Anpassungsfähigkeit**   | Träge, reagiert langsamer auf plötzliche Änderungen.           | Schneller, passt sich plötzlichen Änderungen an. |
| **Berechnungsaufwand**     | Einfach zu berechnen.                                             | Etwas komplexer durch Gewichtung.                  |
| **Vergangene Datenpunkte** | Feste Fenstergröße, ältere Daten werden nicht berücksichtigt. | Berücksichtigt alle vergangenen Daten.            |

---

### **Kombinatorik – Übersicht**

Die **Kombinatorik** ist ein Teilgebiet der Mathematik, das sich mit der **Anzahl von Möglichkeiten** beschäftigt, Objekte zu kombinieren oder anzuordnen.

---

### **Vier kombinatorische Betrachtungen**

1. **Mit Zurücklegen, mit Reihenfolge (Variation mit Wiederholung)**
   * **Bedeutung** : Ein Objekt kann **mehrfach** ausgewählt werden, und die **Reihenfolge** spielt eine Rolle.
   * **Formel** : nkn^k**n**k
   * nn**n**: Anzahl der Objekte
   * kk**k**: Anzahl der Ziehungen
   * **Anwendung** : Passwörter, bei denen Buchstaben/Zahlen wiederholt werden dürfen.
2. **Ohne Zurücklegen, mit Reihenfolge (Variation ohne Wiederholung)**
   * **Bedeutung** : Ein Objekt kann **nur einmal** ausgewählt werden, und die **Reihenfolge** spielt eine Rolle.
   * **Formel** : n!(n−k)!\frac{n!}{(n-k)!}**(**n**−**k**)!**n**!**
   * nn**n**: Anzahl der Objekte
   * kk**k**: Anzahl der Ziehungen
   * **Anwendung** : Sitzordnungen, Wettkämpfe mit Rangfolge.
3. **Mit Zurücklegen, ohne Reihenfolge (Kombination mit Wiederholung)**
   * **Bedeutung** : Ein Objekt kann **mehrfach** ausgewählt werden, die **Reihenfolge** ist egal.
   * **Formel** : (n+k−1k)\binom{n + k - 1}{k}**(**k**n**+**k**−**1****)**
   * nn**n**: Anzahl der Objekte
   * kk**k**: Anzahl der Ziehungen
   * **Anwendung** : Auswahl von Kugeln aus einer Kiste, wobei Farben wiederholt werden dürfen.
4. **Ohne Zurücklegen, ohne Reihenfolge (Kombination ohne Wiederholung)**
   * **Bedeutung** : Ein Objekt kann **nur einmal** ausgewählt werden, die **Reihenfolge** ist egal.
   * **Formel** : (nk)=n!k!(n−k)!\binom{n}{k} = \frac{n!}{k!(n-k)!}**(**k**n****)**=**k**!**(**n**−**k**)!**n**!**
   * nn**n**: Anzahl der Objekte
   * kk**k**: Anzahl der Ziehungen
   * **Anwendung** : Lottospiel (6 aus 49), Ziehen von Karten aus einem Kartenspiel.

---

### **Zusammenfassung**

| **Art der Kombination**       | **Zurücklegen?** | **Reihenfolge?** | **Formel**                                                               | **Beispiel**               |
| ----------------------------------- | ----------------------- | ---------------------- | ------------------------------------------------------------------------------ | -------------------------------- |
| Mit Zurücklegen, mit Reihenfolge   | Ja                      | Ja                     | nkn^k**n**k                                                              | Passwörter, Zahlenkombinationen |
| Ohne Zurücklegen, mit Reihenfolge  | Nein                    | Ja                     | n!(n−k)!\frac{n!}{(n-k)!}**(**n**−**k**)!**n**!**    | Sitzordnungen, Ranglisten        |
| Mit Zurücklegen, ohne Reihenfolge  | Ja                      | Nein                   | (n+k−1k)\binom{n+k-1}{k}**(**k**n**+**k**−**1****)** | Auswahl von Kugeln mit Farben    |
| Ohne Zurücklegen, ohne Reihenfolge | Nein                    | Nein                   | (nk)\binom{n}{k}**(**k**n****)**                                   | Lotto, Ziehen von Karten         |

---

### **Wann verwendet man Kombinatorik?**

* **Optimierung** : Planung von Sitzplätzen, Routen oder Schichten.
* **Wahrscheinlichkeitsrechnung** : Berechnung der Gewinnchancen (z. B. Lotto, Poker).
* **Datenanalyse** : Zählen von Möglichkeiten in großen Datensätzen.

---

### **Zufallsexperimente und wichtige Begriffe**

Ein **Zufallsexperiment** ist ein Vorgang, dessen **Ausgang ungewiss** ist, jedoch durch bestimmte Regeln beschrieben werden kann. Beispiele: Würfeln, Münzwurf, Ziehen einer Karte.

---

### **Wichtige Begriffe**

1. Ergebnisraum (Ω)
   * Die Menge aller **möglichen Ergebnisse** eines Zufallsexperiments.
   * Beispiel: Beim Würfeln ist Ω={1,2,3,4,5,6}
2. **Elementares Ereignis**
   * Ein einzelnes Ergebnis aus dem Ergebnisraum.
   * Beispiel: {3} beim Würfeln ist ein elementares Ereignis.
3. **Ereignis (A**)
   * Eine Teilmenge des Ergebnisraums; kann **ein oder mehrere Ergebnisse** enthalten.
   * Beispiel: „Gerade Zahl würfeln“ ist A={2,4,6}
4. **Sicheres Ereignis**
   * Enthält **alle möglichen Ergebnisse** des Experiments.
   * Beispiel: Beim Würfeln ist das sichere Ereignis A=Ω={1,2,3,4,5,6}
5. **Unmögliches Ereignis**
   * Enthält  **kein einziges Ergebnis** ; es tritt nie ein.
   * Beispiel: „Eine 7 würfeln“ ist A=∅A {}

---

### **Verbindung zur Mengenlehre**

Die Begriffe aus Zufallsexperimenten lassen sich durch **Mengenlehre** beschreiben:

* **Ergebnisraum** (Ω\): Die Grundmenge.
* **Ereignisse** : Teilmengen von Ω.
* **Sicheres Ereignis** : Die Menge Ω selbst.
* **Unmögliches Ereignis** : Die leere Menge {}.
* **Elementares Ereignis** : Ein einzelnes Element von Ω.

 **Operationen mit Ereignissen** :

* **Vereinigung** (A∪B oder **A**∪**B**): „A oder B tritt ein.“
* **Schnittmenge** (A∩B): „A und B treten gleichzeitig ein.“
* **Komplement** (A'): „A tritt nicht ein“ (alle Elemente aus Ω, die nicht in **A** sind).

---

# Wahrscheinlichkeitsbegriffe

## 1. **Laplace- oder Klassischer Wahrscheinlichkeitsbegriff**

* **Definition** : Die Wahrscheinlichkeit eines Ereignisses wird durch das Verhältnis der günstigen Fälle zu allen möglichen (gleich wahrscheinlichen) Fällen im Ergebnisraum berechnet.
* **Formel** :
  P(A)=Anzahl der günstigen Fälle / Anzahl aller möglichen Fälle
* **Anwendung** : Nur anwendbar, wenn alle Ergebnisse gleich wahrscheinlich sind.
* **Beispiel** :
* Beim Werfen eines fairen Würfels beträgt die Wahrscheinlichkeit für eine 3:
  P(3)= 1/6

---

## 2. **Statistischer Wahrscheinlichkeitsbegriff**

* **Definition** : Die Wahrscheinlichkeit eines Ereignisses basiert auf der relativen Häufigkeit des Ereignisses in vielen Wiederholungen eines Experiments.
* **Merkmal** : Je häufiger das Experiment durchgeführt wird, desto stabiler wird die relative Häufigkeit (Gesetz der großen Zahlen).
* **Beispiel** :
* Werfen eines Würfels 100-mal:
  * Eine 3 wurde 18-mal beobachtet.
  * Die statistische Wahrscheinlichkeit für die 3 ist:
    P(3)≈18 / 100

---

## 3. **Subjektiver Wahrscheinlichkeitsbegriff**

* **Definition** : Die Wahrscheinlichkeit eines Ereignisses wird basierend auf persönlichem Glauben, Einschätzungen oder Erfahrungen angegeben.
* **Merkmal** : Beruht nicht auf mathematischen Berechnungen oder relativen Häufigkeiten.
* **Beispiel** :
* Ein Wetterexperte schätzt die Wahrscheinlichkeit für Regen morgen auf 70 %, basierend auf Wettermodellen und persönlicher Erfahrung.

# Axiome von Kolmogorov

## 1. **Nichtnegative Wahrscheinlichkeit**

* **Axiom** : Für jedes Ereignis **A** gilt:
  P(A) ≥ 0
* **Bedeutung** : Die Wahrscheinlichkeit eines Ereignisses kann niemals negativ sein.

 **Beispiel** :
Die Wahrscheinlichkeit, beim Würfeln eine Zahl zwischen 1 und 6 zu werfen, ist mindestens 0 (z. B. P(A) = 1/6)

---

## 2. **Sichere Wahrscheinlichkeit**

* **Axiom** : Die Wahrscheinlichkeit des sicheren Ereignisses **S** (d. h. des gesamten Ergebnisraums) ist immer 1:
  P(S)=1
* **Bedeutung** : Es ist sicher, dass irgendein Ergebnis im Ergebnisraum **S** eintritt.

 **Beispiel** :
Beim Würfeln mit einem fairen Würfel ist sicher, dass eine Zahl zwischen 1 und 6 erscheint, also P(S)=1

---

## 3. **Additivität**

* **Axiom** : Wenn zwei Ereignisse **A** und **B** disjunkt sind (d. h., sie können nicht gleichzeitig eintreten), dann gilt:
  P(A∪B) = P(A) + P(B)
  Das bedeutet: Die Wahrscheinlichkeit, dass **entweder A*** oder **B** eintritt, ist die Summe der Wahrscheinlichkeiten von **A** und **B**,  **falls sie sich nicht überschneiden** .

---

### Beispiel: Würfeln mit einem fairen Würfel

* **Ereignis A** Die Zahl 1 wird gewürfelt.
  Wahrscheinlichkeit:
  P(A)=1/6
* **Ereignis B** Die Zahl 2 wird gewürfelt.
  Wahrscheinlichkeit:
  P(B)=1/6
* **Sind A und B disjunkt?**
  **Ja, weil man beim Würfeln nur eine Zahl auf einmal erhalten kann. Es ist unmöglich, dass sowohl die 1 als auch die 2 gleichzeitig geworfen werden. Daher A∩B=∅**
* **Was ist die Wahrscheinlichkeit, dass A** oder **B** eintritt?
  Die Wahrscheinlichkeit ist die Summe der Einzelwahrscheinlichkeiten:
  P(A∪B) = P(A) + P(B) = 1/6 + 1/6 = 2/6 = 1/3
* Das bedeutet es gibt eine 1/3 Wahrscheinlichkeit, dass entweder eine 1 oder eine 2 geworfen wird.

### Fazit:

Werden die drei Axiome von Kolmogorov erfüllt, so besteht eine gültige Wahrscheinlichkeitsfunktion.

---

### Bedingte Wahrscheinlichkeit und stochastische Unabhängigkeit

---

#### **1. Bedingte Wahrscheinlichkeit**

Die bedingte Wahrscheinlichkeit beschreibt die Wahrscheinlichkeit, dass ein Ereignis **A** eintritt,  **unter der Bedingung** , dass ein anderes Ereignis **B** bereits eingetreten ist. Sie wird definiert durch die Formel:

P(A | B) = P(A ∩ B) / P(B)

* **P(A | B)** : Die Wahrscheinlichkeit von **A**, unter der Bedingung, dass **B** eingetreten ist.
* **P(A ∩ B)** : Die Wahrscheinlichkeit, dass sowohl **A** als auch **B** eintreten.
* **P(B)** : Die Wahrscheinlichkeit, dass **B** eintritt, wobei P(B)>0

**Beispiel:**
Ein Würfel wird geworfen.

* Ereignis **A**: Es wird eine gerade Zahl geworfen ({2, 4, 6}).
* Ereignis **B**: Es wird eine Zahl größer als 3 geworfen ({4, 5, 6}).

Die bedingte Wahrscheinlichkeit P(A∣B) ist die Wahrscheinlichkeit, dass eine gerade Zahl geworfen wird, wenn bekannt ist, dass die Zahl größer als 3 ist.

* A∩B={4,6}
* P(A∩B) =2/6 = 1/3
* P(B)=3/6=1/2

Daraus folgt:

P(A | B) = P(A ∩ B) / P(B) = (1/3) / (1/2) = 2/3.

---

#### **2. Stochastische Unabhängigkeit**

Zwei Ereignisse **A** und **B** sind  **stochastisch unabhängig** , wenn das Eintreten des einen Ereignisses **keinen Einfluss** auf die Wahrscheinlichkeit des anderen Ereignisses hat. Dies wird wie folgt definiert:

P(A ∩ B) = P(A) ⋅ P(B)

* **P(A ∩ B):** Wahrscheinlichkeit, dass A und **B** gemeinsam eintreten.
* Wenn diese Gleichung gilt, dann gilt auch:

P(A | B) = P(A) und P(B | A) = P(B).

**Beispiel:**
Ein Münzwurf:

* Ereignis **A**: Die Münze zeigt Kopf.
* Ereignis **B**: Die Münze zeigt Zahl.

Da der Ausgang des einen Ereignisses keinen Einfluss auf das andere hat:

P(A ∩ B) = P(A) ⋅ P(B) = (1/2) ⋅ (1/2) = 1/4.

Die Ereignisse **A** und **B** sind stochastisch unabhängig.

---

### Zusammenfassung:

1. **Bedingte Wahrscheinlichkeit** beschreibt die Wahrscheinlichkeit eines Ereignisses, wenn ein anderes Ereignis bereits eingetreten ist.
   * Formel: P(A | B) = P(A ∩ B) / P(B).
2. **Stochastische Unabhängigkeit** bedeutet, dass das Eintreten eines Ereignisses keine Auswirkung auf ein anderes hat.
   * Bedingung: P(A ∩ B) = P(A) ⋅ P(B).
3. **Verknüpfung** : Bei unabhängigen Ereignissen bleibt die bedingte Wahrscheinlichkeit unverändert: P(A | B) = P(A).

---

## Zufallsvariablen

#### diskrete Zufallsvariablen

1. es gibt endlich viele Ausprägungen
2. zwischen zwei aufeinander folgenden x-Werten liegen keine weiteren möglichen x-werte
3. für jede Ausprägung xi gibt es eine Wahrscheinlichkeit, diese Zuordnung nennt man Massenfunktion

Die Formel beschreibt die Wahrscheinlichkeitsfunktion f(x) einer diskreten Zufallsvariable X:

f(x) = P(X = x)

f(x) = p_i, falls x = x_i,
f(x) = 0, sonst.

Bedeutung der Bestandteile:

1. f(x): Eine Funktion, die jedem Wert x eine Wahrscheinlichkeit zuordnet.
2. P(X = x): Die Wahrscheinlichkeit, dass die Zufallsvariable X den Wert x annimmt.
3. x_i: Ein möglicher Wert, den X annehmen kann (Index i kennzeichnet verschiedene Werte).
4. p_i: Die Wahrscheinlichkeit, dass X = x_i. Jede Wahrscheinlichkeit ist mit einem Wert x_i verknüpft.
5. „0 sonst“: Für alle Werte von x, die X nicht annehmen kann, ist die Wahrscheinlichkeit 0.

Beispiel:
Für einen Würfelwurf (X ist die Augenzahl):

* x_i = 1, 2, 3, 4, 5, 6,
* p_i = 1/6 für alle x_i,
* f(x) = 0 für alle anderen Werte (x nicht in {1, 2, 3, 4, 5, 6}).

Interpretation:
Die Funktion f(x) gibt die Wahrscheinlichkeiten für die möglichen Werte von X an.

---

### Verteilungsfunktion

Die Verteilungsfunktion **F**(**x**) einer Zufallsvariable **X** beschreibt die Wahrscheinlichkeit, dass die Zufallsvariable **X** einen Wert kleiner oder gleich **x** annimmt. Mit der Verteilungsfunktion wird also nicht die Wahrscheinlichkeit eines einzelnen konkreten Wertes betrachtet, sondern die Wahrscheinlichkeit, dass ein bestimmter Wert nicht überschritten wird.

F(x) = P(X ≤ x)

Bedeutung der Bestandteile:

1. F(x): Die kumulierte Wahrscheinlichkeit, dass die Zufallsvariable X höchstens den Wert x erreicht.
2. P(X ≤ x): Die Wahrscheinlichkeit, dass X alle Werte bis einschließlich x annimmt.
3. X: Eine Zufallsvariable, die bestimmte Werte annehmen kann.

Eigenschaften der Verteilungsfunktion:

1. F(x) ist immer nicht abnehmend: Für x1 ≤ x2 gilt F(x1) ≤ F(x2).
2. Grenzwerte:
   * lim(x → -∞) F(x) = 0
   * lim(x → +∞) F(x) = 1
3. Diskrete Sprünge: Bei diskreten Zufallsvariablen steigt F(x) an den Stellen, an denen die Zufallsvariable X Werte annimmt. Die Sprunghöhe entspricht der Wahrscheinlichkeit P(X = x).

Beispiel:
Für einen Würfelwurf (X ist die Augenzahl):

* P(X = 1) = 1/6, P(X = 2) = 1/6, ..., P(X = 6) = 1/6.
* Die Verteilungsfunktion F(x) ist:
  * F(x) = 0, für x < 1
  * F(x) = 1/6, für 1 ≤ x < 2
  * F(x) = 2/6, für 2 ≤ x < 3
  * F(x) = 3/6, für 3 ≤ x < 4
  * F(x) = 4/6, für 4 ≤ x < 5
  * F(x) = 5/6, für 5 ≤ x < 6
  * F(x) = 1, für x ≥ 6

Interpretation:
Die Verteilungsfunktion F(x) zeigt, wie sich die Wahrscheinlichkeiten kumulieren, während x wächst. Sie steigt stufenweise an den diskreten Werten von X.

---

### Stetige Zufallsvariable

1. Eine stetige Zufallsvariable kann beliebige Werte innerhalb eines Intervalls annehmen. Sie wird durch die **Wahrscheinlichkeitsdichtefunktion (PDF)** **f**(**x**) beschrieben, die keine Wahrscheinlichkeiten für einzelne Werte liefert (P(X=x)=0P), sondern die Verteilung der Wahrscheinlichkeiten über die Werte zeigt.

   Die Wahrscheinlichkeit, dass **X** in einem Intervall **[**a**,**b**]** liegt, wird durch das Integral der Dichtefunktion berechnet:

   P(a≤X≤b)=∫ab = Integral von unetre grenze a bis obere grenze b f(x) dx

---

### Erwartungswert Zufallsvariblen

Der Erwartungswert einer Zufallsvariablen beschreibt den Durchschnittswert, den man bei unendlich vielen Wiederholungen eines Zufallsexperiments erwarten würde. Er ist eine zentrale Maßzahl zur Beschreibung der Verteilung.

1. **Diskrete Zufallsvariablen:**
   Für eine diskrete Zufallsvariable **X** mit den möglichen Werten **x**i und den Wahrscheinlichkeiten P(X=xi)=pi wird der Erwartungswert berechnet als:
   E(X)=∑xi⋅pi
2. **Stetige Zufallsvariablen:**
   Für eine stetige Zufallsvariable **X** mit der Wahrscheinlichkeitsdichtefunktion **f**(**x**) wird der Erwartungswert berechnet als:
   E(X)=∫−∞∞x⋅f(x)  dx

**Interpretation:**
Der Erwartungswert ist der Schwerpunkt der Verteilung und zeigt, wo der „mittlere“ Wert liegt. Er entspricht jedoch nicht immer einem tatsächlich möglichen Wert der Zufallsvariablen.

---

### Varianz von Zufallsvariablen

Di eVarianz ist ein Maß der Streuung einer Zufallsvaribable um den Erwartungswert. Ist hie rähnlich zur empirischen V arianz nur das statt tatsächlich aufgetretener Messwerte, theoretisch mögliche Messwerte berechnet werden.

 Formel für die Varianz:

varX = E(X-EX)^2

diskret:

varX = ∑(xi-EX)^2 * f(xi)

stetig:

varx = ∫−∞∞ (x-EX)^2 ⋅f(x)  dx

---

### Gleichverteilung

**Diskrete Gleichverteilung:**
Eine diskrete Gleichverteilung liegt vor, wenn alle möglichen Werte einer diskreten Zufallsvariablen die gleiche Wahrscheinlichkeit haben. Die Wahrscheinlichkeitsfunktion ist konstant und wird wie folgt definiert:

* Beispiel: Bei einem fairen Würfel hat jeder der sechs möglichen Werte ({1, 2, 3, 4, 5, 6}) die Wahrscheinlichkeit P(X=x)=1 / 6

**Stetige Gleichverteilung:**
Eine stetige Gleichverteilung liegt vor, wenn die Werte einer stetigen Zufallsvariablen gleichmäßig über ein Intervall [a,b] verteilt sind. Die Wahrscheinlichkeitsdichtefunktion ist konstant und wird wie folgt definiert:

* Die Dichtefunktion **f**(**x**) ist:
  f(x)=1b−a für x∈[a,b]
* Die Wahrscheinlichkeit, dass **X** in einem Teilintervall **[**c**,**d**]** liegt, ist proportional zur Länge des Intervalls
* Beispiel: Die Zufallsvariable **X**, die die Zeit beschreibt, die ein Bus in einem Intervall von 0 bis 10 Minuten ankommt, ist gleichverteilt. Hier wäre f(x)=1/10  für x∈[0,10]

**Unterschied:**

* Bei der diskreten Gleichverteilung gibt es eine endliche oder abzählbare Anzahl von Werten mit gleicher Wahrscheinlichkeit.
* Bei der stetigen Gleichverteilung gibt es unendlich viele Werte in einem Intervall, und die Wahrscheinlichkeit ist über dieses Intervall gleichmäßig verteilt.

---

### Bernoulli-Modell


Das Bernoulli-Modell beschreibt ein Experiment, das genau zwei mögliche Ergebnisse hat, typischerweise als Erfolg (1) und Misserfolg (0) bezeichnet. Es wird häufig verwendet, um Zufallsprozesse mit dichotomen (zweiwertigen) Ergebnissen zu modellieren.

### Eigenschaften des Bernoulli-Modells:

1. **Definition der Zufallsvariablen** :
   Die Zufallsvariable **X** kann zwei Werte annehmen:
   X=1(Erfolg) mit Wahrscheinlichkeit **p**,
   X=0 (Misserfolg) mit Wahrscheinlichkeit 1-p
2. **Wahrscheinlichkeitsfunktion** :
   Die Wahrscheinlichkeitsfunktion des Bernoulli-Modells ist:
   P(X = x) = p^x * (1 - p)^(1 - x)
   wobei **x**∈**{**0**,**1**}**

* Für x=1 ist P(X=1)=p
* Für x=0 ist P(X=0)=1−p

1. Der Erwartungswert gibt den durchschnittlichen Wert der Zufallsvariablen an:
   E(X) = p.
2. **Varianz** :
   Die Varianz misst die Streuung der Zufallsvariablen:
   Var(X) = p * (1 - p).
3. **Unabhängigkeit** :
   In einer Bernoulli-Kette, die aus mehreren unabhängigen Bernoulli-Experimenten besteht, sind die einzelnen Ergebnisse voneinander unabhängig.

### Beispiel:

Ein Münzwurf kann als Bernoulli-Experiment modelliert werden:

* Erfolg (X=1): Kopf mit p = 0.5
* Misserfolg (X=0): Zahl mit 1−p = 0.5

Hier wäre die Wahrscheinlichkeitsfunktion:
P(X = 1) = 0.5 und P(X = 0) = 0.5.

### Anwendung:

Das Bernoulli-Modell ist die Grundlage für viele statistische Modelle und wird z. B. in der Modellierung von Binomialverteilungen, in der Fehleranalyse oder bei Ja/Nein-Fragen verwendet.
