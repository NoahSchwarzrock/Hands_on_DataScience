{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "import numpy as np\n",
    "# BaseEstimator stellt grundlegende Funktionlitäten bereit, die \"Estimators\" beinhalten sollen, Kompatible und ein heitlich\n",
    "# fit, predict, set_params, get_params\n",
    "# ClusterMixin spezuiell für Clustering Algorhitmen, stellt sicher dass das Modell eine fit_predict(x) methode besitzt\n",
    "\n",
    "class MyKmeans(BaseEstimator, ClusterMixin):\n",
    "    \n",
    "    def __init__(self, n_clusters=2, max_iter=300, tol=0.0001, init=\"random\", random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.init = init\n",
    "        self.random_state = random_state\n",
    "        self.cluster_centers_ = None\n",
    "        self.labels_ = None\n",
    "        self.inertia_ = None\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "    def euclid_distance(self, a, b):\n",
    "        return np.sum((a-b)**2)\n",
    "    \n",
    "    def calculate_centroid_matching(self, X, c):\n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - c, axis=2)\n",
    "        return np.argmin(distances, axis=1)\n",
    "        \n",
    "    def calculate_centroids(self, X, labels):\n",
    "        pass\n",
    "    \n",
    "    def calculate_min_max_for_each_column(self, array):\n",
    "        return np.min(array, axis=0), np.max(array, axis=0)\n",
    "    \n",
    "    def _initialize_centroids(self, X):\n",
    "        if isinstance(self.init, np.ndarray):\n",
    "            self.cluster_centers_ = self.init\n",
    "        else:\n",
    "            X_min, X_max = self.calculate_min_max_for_each_column(X)\n",
    "            rand_factor = np.random.rand(self.n_clusters, X.shape[1])\n",
    "            self.cluster_centers_ =  X_min + rand_factor * (X_max - X_min)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self._initialize_centroids(X)\n",
    "        \n",
    "        for _ in range(self.max_iter):\n",
    "            labels = self.calculate_centroid_matching(X, self.cluster_centers_)\n",
    "            \n",
    "            new_centroids = np.array([\n",
    "                X[labels == i].mean(axis=0) if np.any(labels == i) else self.cluster_centers_[i] \n",
    "                for i in range(self.n_clusters)\n",
    "            ])\n",
    "            \n",
    "            shift = self.euclid_distance(new_centroids, self.cluster_centers_)\n",
    "            \n",
    "            if shift < self.tol:\n",
    "                break\n",
    "            \n",
    "            self.cluster_centers_ = new_centroids\n",
    "            \n",
    "        self.labels_ = labels\n",
    "        self.inertia_ = self.euclid_distance(X, self.cluster_centers_[self.labels_])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.calculate_centroid_matching(X, self.cluster_centers_)\n",
    "    \n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [3, 9], [3, 8]])\n",
    "\n",
    "kmeans = MyKmeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "kmeans.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
